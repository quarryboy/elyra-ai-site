{"componentChunkName":"component---src-pages-recipes-configuring-apache-mdx","path":"/recipes/configuring-apache/","result":{"pageContext":{"frontmatter":{"title":"Configuring Apache Airflow on Kubernetes for use with Elyra","description":"Configuring Apache Airflow on Kubernetes for use with Elyra"},"relativePagePath":"/recipes/configuring-apache.mdx","titleType":"page","MdxNode":{"id":"f08bd06a-cb05-5abc-a821-2bbe73367536","children":[],"parent":"994f4788-3a54-5eac-81e6-934d99a0c272","internal":{"content":"---\ntitle: Configuring Apache Airflow on Kubernetes for use with Elyra\ndescription: Configuring Apache Airflow on Kubernetes for use with Elyra\n---\n\nexport const Title = () => (\n  <span>\n    Configuring Apache Airflow on Kubernetes for use with Elyra\n  </span>\n);\n\n<PageDescription>\n\nPipelines in Elyra can be run locally in JupyterLab, or remotely on Kubeflow Pipelines or Apache Airflow to take advantage of shared resources that speed up processing of compute intensive tasks.\n\n</PageDescription>\n\n<InlineNotification>\n\n**Note:** Support for Apache Airflow is experimental.\n\n</InlineNotification>\n\nThis document outlines how to set up a new Elyra-enabled Apache Airflow environment or add Elyra support to an existing deployment.\n  \nThis guide assumes a general working knowledge of and administration of a Kubernetes cluster.\n\n## Prerequisites\n  \n- A private repository on github.com or GitHub Enterprise that is used to store DAGs.\n- S3-based cloud object storage e.g. IBM Cloud Object Storage, Amazon S3, MinIO\n\nAND  \n  \n- A Kubernetes Cluster without Apache Airflow installed\n    - Ensure Kubernetes is at least v1.18. Earlier versions might work  but have not been tested.\n    - Helm v3.0 or later\n    - Use the [Helm chart](https://github.com/airflow-helm/charts/tree/main/charts/airflow) available in the Airflow source distribution with the [Elyra sample configuration](https://raw.githubusercontent.com/elyra-ai/elyra/v3.0.1/etc/kubernetes/airflow/helm/values.yaml).\n    \nOR  \n  \n- An existing Apache Airflow cluster \n    - Ensure Apache Airflow is at least v1.10.8 and below v2.0.0. Other versions might work but have not been tested.\n    - Apache Airflow is configured to use the Kubernetes Executor.\n    - Ensure the KubernetesPodOperator is installed and available in the Apache Airflow deployment\n    \n## Setting up a DAG repository on GitHub\n\nIn order to use Apache Airflow with Elyra, it must be configured to use a GitHub repository to store DAGs.\n\n- Create a private repository on github.com or GitHub Enterprise. (Elyra produces DAGs that contain credentials, which are not encrypted. Therefore you should not use a public repository.)\n- [Generate a personal access token](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) with push access to the repository. This token is used by Elyra to upload DAGs.\n- [Generate an SSH key](https://docs.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account) with read access for the repository. Apache Airflow uses a git-sync container to keep its collection of DAGs in synch with the content of the GitHub Repository and the SSH key is used to authenticate.\n\nTake note of the following information:\n - GitHub API endpoint (e.g. `https://api.github.com` if the repository is hosted on github.com)\n - Repository name (e.g. `your-git-org/your-dag-repo`)\n - Repository branch name (e.g. `main`)\n - Personal access token (e.g. `4d79206e616d6520697320426f6e642e204a616d657320426f6e64`)\n\nYou need to provide this information in addition to your cloud object storage credentials when you [create a runtime configuration](../user_guide/runtime-conf) in Elyra for the Apache Airflow deployment.\n\n![Example Apache Airflow runtime configuration](../images/ai/airflow-runtime-config-sample.png)\n\n## Deploying Airflow on a new Kubernetes cluster\n  \nTo deploy Apache Airflow on a new Kubernetes cluster:\n\n1. Create a Kubernetes secret containing the SSH key that you [created earlier](#setting-up-a-dag-repository-on-github).\n The example below creates a secret named `airflow-secret` from three files. Replace the secret name, file names and locations as appropriate for your environment. \n     \n   ```bash\n   kubectl create secret generic airflow-secret --from-file=id_rsa=.ssh/id_rsa --from-file=known_hosts=.ssh/known_hosts --from-file=id_rsa.pub=.ssh/id_rsa.pub -n airflow\n   ```\n  \n2. Download, review, and customize the [sample `helm` configuration](https://raw.githubusercontent.com/elyra-ai/elyra/v3.0.1/etc/kubernetes/airflow/helm/values.yaml) (or customize an existing configuration):\n   - Set `git.url` to the URL of the private repository you created earlier, e.g. `ssh://git@github.com/your-git-org/your-dag-repo`\n   - Set `git.ref` to the DAG branch, e.g. `main`.\n   - Set `git.secret` to the name of the secret you created, e.g. `airflow-secret`.\n   - Adjust the `git.gitSync.refreshTime` as desired.\n\n   Example excerpt from a customized configuration:\n\n   ```bash\n   ## configs for the DAG git repository & sync container\n   ##\n   git:\n     ## url of the git repository\n     ##\n     ## EXAMPLE: (HTTP)\n     ##   url: \"https://github.com/torvalds/linux.git\"\n     ##\n     ## EXAMPLE: (SSH)\n     ##   url: \"ssh://git@github.com:torvalds/linux.git\"\n     ##\n     url: \"ssh://git@github.com/your-git-org/your-dag-repo\"\n\n     ## the branch/tag/sha1 which we clone\n     ##\n     ref: \"main\"\n\n     ## the name of a pre-created secret containing files for ~/.ssh/\n     ##\n     ## NOTE:\n     ## - this is ONLY RELEVANT for SSH git repos\n     ## - the secret commonly includes files: id_rsa, id_rsa.pub, known_hosts\n     ## - known_hosts is NOT NEEDED if `git.sshKeyscan` is true\n     ##\n     secret: \"airflow-secret\"\n     ...\n     gitSync:\n       ...\n       refreshTime: 10\n   ```\n\n   ```bash\n   airflow:\n   ## configs for the docker image of the web/scheduler/worker\n   ##\n   image:\n     repository: elyra/airflow\n   ```    \n  \n   The container image is created using [this `Dockerfile`](https://github.com/elyra-ai/elyra/tree/v3.0.1/etc/docker/airflow) and published on [Docker Hub](https://hub.docker.com/r/elyra/airflow) and [quay.io](https://quay.io/repository/elyra/airflow).\n\n3. Install Apache Airflow using the customized configuration.\n  \n   ```bash\n   helm install \"airflow\" stable/airflow --values path/to/your_customized_helm_values.yaml\n   ```\n\nOnce Apache Airflow is deployed you are ready to create and run pipelines, as described in the [tutorial](../getting_started/tutorials).\n\n## Enabling Elyra pipelines in an existing Apache Airflow deployment\n\nTo enable running of notebook pipelines on an existing Apache Airflow deployment  \n- Enable Git as DAG storage by customizing the [Git settings in `airflow.cfg`](https://github.com/apache/airflow/blob/6416d898060706787861ff8ecbc4363152a35f45/airflow/config_templates/default_airflow.cfg#L913).\n\nOnce Apache Airflow is deployed you are ready to create and run pipelines, as described in the [tutorial](../getting_started/tutorials).\n","type":"Mdx","contentDigest":"ae7ae9c6c49b5266147440a35eca30ac","owner":"gatsby-plugin-mdx","counter":337},"frontmatter":{"title":"Configuring Apache Airflow on Kubernetes for use with Elyra","description":"Configuring Apache Airflow on Kubernetes for use with Elyra"},"exports":{},"rawBody":"---\ntitle: Configuring Apache Airflow on Kubernetes for use with Elyra\ndescription: Configuring Apache Airflow on Kubernetes for use with Elyra\n---\n\nexport const Title = () => (\n  <span>\n    Configuring Apache Airflow on Kubernetes for use with Elyra\n  </span>\n);\n\n<PageDescription>\n\nPipelines in Elyra can be run locally in JupyterLab, or remotely on Kubeflow Pipelines or Apache Airflow to take advantage of shared resources that speed up processing of compute intensive tasks.\n\n</PageDescription>\n\n<InlineNotification>\n\n**Note:** Support for Apache Airflow is experimental.\n\n</InlineNotification>\n\nThis document outlines how to set up a new Elyra-enabled Apache Airflow environment or add Elyra support to an existing deployment.\n  \nThis guide assumes a general working knowledge of and administration of a Kubernetes cluster.\n\n## Prerequisites\n  \n- A private repository on github.com or GitHub Enterprise that is used to store DAGs.\n- S3-based cloud object storage e.g. IBM Cloud Object Storage, Amazon S3, MinIO\n\nAND  \n  \n- A Kubernetes Cluster without Apache Airflow installed\n    - Ensure Kubernetes is at least v1.18. Earlier versions might work  but have not been tested.\n    - Helm v3.0 or later\n    - Use the [Helm chart](https://github.com/airflow-helm/charts/tree/main/charts/airflow) available in the Airflow source distribution with the [Elyra sample configuration](https://raw.githubusercontent.com/elyra-ai/elyra/v3.0.1/etc/kubernetes/airflow/helm/values.yaml).\n    \nOR  \n  \n- An existing Apache Airflow cluster \n    - Ensure Apache Airflow is at least v1.10.8 and below v2.0.0. Other versions might work but have not been tested.\n    - Apache Airflow is configured to use the Kubernetes Executor.\n    - Ensure the KubernetesPodOperator is installed and available in the Apache Airflow deployment\n    \n## Setting up a DAG repository on GitHub\n\nIn order to use Apache Airflow with Elyra, it must be configured to use a GitHub repository to store DAGs.\n\n- Create a private repository on github.com or GitHub Enterprise. (Elyra produces DAGs that contain credentials, which are not encrypted. Therefore you should not use a public repository.)\n- [Generate a personal access token](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) with push access to the repository. This token is used by Elyra to upload DAGs.\n- [Generate an SSH key](https://docs.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account) with read access for the repository. Apache Airflow uses a git-sync container to keep its collection of DAGs in synch with the content of the GitHub Repository and the SSH key is used to authenticate.\n\nTake note of the following information:\n - GitHub API endpoint (e.g. `https://api.github.com` if the repository is hosted on github.com)\n - Repository name (e.g. `your-git-org/your-dag-repo`)\n - Repository branch name (e.g. `main`)\n - Personal access token (e.g. `4d79206e616d6520697320426f6e642e204a616d657320426f6e64`)\n\nYou need to provide this information in addition to your cloud object storage credentials when you [create a runtime configuration](../user_guide/runtime-conf) in Elyra for the Apache Airflow deployment.\n\n![Example Apache Airflow runtime configuration](../images/ai/airflow-runtime-config-sample.png)\n\n## Deploying Airflow on a new Kubernetes cluster\n  \nTo deploy Apache Airflow on a new Kubernetes cluster:\n\n1. Create a Kubernetes secret containing the SSH key that you [created earlier](#setting-up-a-dag-repository-on-github).\n The example below creates a secret named `airflow-secret` from three files. Replace the secret name, file names and locations as appropriate for your environment. \n     \n   ```bash\n   kubectl create secret generic airflow-secret --from-file=id_rsa=.ssh/id_rsa --from-file=known_hosts=.ssh/known_hosts --from-file=id_rsa.pub=.ssh/id_rsa.pub -n airflow\n   ```\n  \n2. Download, review, and customize the [sample `helm` configuration](https://raw.githubusercontent.com/elyra-ai/elyra/v3.0.1/etc/kubernetes/airflow/helm/values.yaml) (or customize an existing configuration):\n   - Set `git.url` to the URL of the private repository you created earlier, e.g. `ssh://git@github.com/your-git-org/your-dag-repo`\n   - Set `git.ref` to the DAG branch, e.g. `main`.\n   - Set `git.secret` to the name of the secret you created, e.g. `airflow-secret`.\n   - Adjust the `git.gitSync.refreshTime` as desired.\n\n   Example excerpt from a customized configuration:\n\n   ```bash\n   ## configs for the DAG git repository & sync container\n   ##\n   git:\n     ## url of the git repository\n     ##\n     ## EXAMPLE: (HTTP)\n     ##   url: \"https://github.com/torvalds/linux.git\"\n     ##\n     ## EXAMPLE: (SSH)\n     ##   url: \"ssh://git@github.com:torvalds/linux.git\"\n     ##\n     url: \"ssh://git@github.com/your-git-org/your-dag-repo\"\n\n     ## the branch/tag/sha1 which we clone\n     ##\n     ref: \"main\"\n\n     ## the name of a pre-created secret containing files for ~/.ssh/\n     ##\n     ## NOTE:\n     ## - this is ONLY RELEVANT for SSH git repos\n     ## - the secret commonly includes files: id_rsa, id_rsa.pub, known_hosts\n     ## - known_hosts is NOT NEEDED if `git.sshKeyscan` is true\n     ##\n     secret: \"airflow-secret\"\n     ...\n     gitSync:\n       ...\n       refreshTime: 10\n   ```\n\n   ```bash\n   airflow:\n   ## configs for the docker image of the web/scheduler/worker\n   ##\n   image:\n     repository: elyra/airflow\n   ```    \n  \n   The container image is created using [this `Dockerfile`](https://github.com/elyra-ai/elyra/tree/v3.0.1/etc/docker/airflow) and published on [Docker Hub](https://hub.docker.com/r/elyra/airflow) and [quay.io](https://quay.io/repository/elyra/airflow).\n\n3. Install Apache Airflow using the customized configuration.\n  \n   ```bash\n   helm install \"airflow\" stable/airflow --values path/to/your_customized_helm_values.yaml\n   ```\n\nOnce Apache Airflow is deployed you are ready to create and run pipelines, as described in the [tutorial](../getting_started/tutorials).\n\n## Enabling Elyra pipelines in an existing Apache Airflow deployment\n\nTo enable running of notebook pipelines on an existing Apache Airflow deployment  \n- Enable Git as DAG storage by customizing the [Git settings in `airflow.cfg`](https://github.com/apache/airflow/blob/6416d898060706787861ff8ecbc4363152a35f45/airflow/config_templates/default_airflow.cfg#L913).\n\nOnce Apache Airflow is deployed you are ready to create and run pipelines, as described in the [tutorial](../getting_started/tutorials).\n","fileAbsolutePath":"/Users/dsobryan/Documents/ElyraOS/elyra-ai-site/src/pages/recipes/configuring-apache.mdx"}}},"staticQueryHashes":["1364590287","137577622","137577622","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}