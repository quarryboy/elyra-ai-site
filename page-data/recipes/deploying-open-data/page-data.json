{"componentChunkName":"component---src-pages-recipes-deploying-open-data-mdx","path":"/recipes/deploying-open-data/","result":{"pageContext":{"frontmatter":{"title":"Deploying Open Data Hub with Elyra","description":"Deploying Open Data Hub with Elyra"},"relativePagePath":"/recipes/deploying-open-data.mdx","titleType":"page","MdxNode":{"id":"51fc2fdc-d995-565a-8239-5191aebdca89","children":[],"parent":"1ef67ff3-0e94-5551-bb76-7082ab81372a","internal":{"content":"---\ntitle: Deploying Open Data Hub with Elyra\ndescription: Deploying Open Data Hub with Elyra\n---\n\nexport const Title = () => (\n  <span>\n    Deploying Open Data Hub with Elyra\n  </span>\n);\n\n<PageDescription>\n\nThis document outlines how to perform a quick deployment of [Kubeflow](https://kubeflow.org), [JupyterHub](https://jupyter.org/hub) and [Elyra](https://github.com/elyra-ai/elyra) on [Open Data Hub (ODH)](https://opendatahub.io/) using the Open Data Hub Operator.\n\n\n</PageDescription>\n\n\nNote the following:\n- The instructions in this document utilize default configurations, which are unlikely to meet the requirements of a production deployment.\n- By completing the steps in this document Kubeflow 1.3, JupyterHub v1.4, and Elyra v2.2.4 are deployed in the `kubeflow` project/namespace.\n- The Kubeflow Central dashboard is unsecured.\n- The JupyterHub GUI is secured by OpenShift. \n \n## Requirements\n\nVerify that the following requirements are met.\n\n- Access to a v4.x Red Hat OpenShift Cluster (16 GB RAM, 6 CPUs, and 45G of disk space) with internet connectivity. \n- The OpenShift CLI (`oc`) is installed locally. \n    - [Installation instructions](https://docs.openshift.com/container-platform/4.7/cli_reference/openshift_cli/getting-started-cli.html) for  Windows and MacOS    \n\n## Prepare for deployment\n\n1. Open the OpenShift web console in a browser and log in.\n1. Copy the login command.\n\n   ![Get oc login command](../images/ai/openshift-get-login-command.png)\n1. Open a terminal window and run the copied command.\n   ```\n   $ oc login --token=TOKEN_VAL --server=https://SERVER:PORT\n   ```\n\n1. Create a new project named `kubeflow`. \n   ```\n   $ oc new-project kubeflow\n   ```\n\n1. Verify that the CLI is using the new `kubeflow` project.\n   ```\n   $ oc project kubeflow\n   ```\n1. Keep the terminal window open.\n\n## Install the Open Data Hub Project Operator on OpenShift\n\nThe Open Data Hub Project Operator manages installation, configuration, and the lifecycle of Open Data Hub projects. The operator is available on OpenShift OperatorHub as a community operator.\n\nTo install the operator:\n\n1. Open the OpenShift web console and log in.\n1. Switch to the `Administrator` view.\n1. Open the projects list (`Home` > `Projects`).\n   ![Open project list in OpenShift](../images/ai/openshift-open-projects.png)\n1. Switch to the `kubeflow` project.\n   ![Open kubeflow project](../images/ai/openshift-view-project.png)  \n1. Open the Operator Hub page (`Operators` > `OperatorHub`).\n1. Search for the `Open Data Hub` operator.\n   ![Install ODH operator](../images/ai/install-odh-operator.png)   \n1. Install the operator, keeping the default values.\n1. Navigate to `Operators` > `Installed Operators` and wait for the operator installation to complete. \n\nNext, you'll install Kubeflow using the operator.\n\n## Deploy Kubeflow on OpenShift\n\nTo deploy Kubeflow using the Open Data Hub operator:\n\n1. Select the `Open Data Hub` operator from the list of installed operators.\n1. On the operator details page select the `Details` tab, if it is not opened by default.\n   ![Deploy application using ODH operator](../images/ai/deploy-app-using-operator.png)\n1. Create a new deployment by clicking `Create instance`.\n1. Select `Configure via YAML view`.\n1. Remove the default deployment configuration in the editor.\n1. Open [this Kubeflow v1.3 deployment file for OpenShift](https://raw.githubusercontent.com/kubeflow/manifests/master/distributions/kfdef/kfctl_openshift_v1.3.0.yaml) in a new browser tab/window.\n1. Copy and paste the content of this file into the editor.\n   ![Deploy Kubeflow using ODH operator](../images/ai/deploy-kubeflow-kfdef.png)\n1. Click `Create` to deploy Kubeflow on the cluster.\n1. In the terminal window monitor the deployment progress by periodically listing pods in the `kubeflow` namespace. Wait until all pods are running. This might take a couple minutes.\n   ```\n   $ oc get pods --namespace kubeflow\n   ```\n   Upon successful deployment you can access the Kubeflow Central dashboard using a public route.\n1. In the terminal window run the following command to retrieve the public Kubeflow Central dashboard URL:\n   ```\n   $ oc get routes -n istio-system istio-ingressgateway -o jsonpath='http://{.spec.host}'\n   ```\n1. Open the displayed URL in a web browser to access the Kubeflow Central dashboard.\n1. Do not select a namespace entry, if you've deployed Kubeflow using the defaults.\n\nThe Kubeflow deployment is complete. As part of this deployment an instance of the MinIO object storage was provisioned. \n\nNext, you'll create a public endpoint for this service that provides you access to the MinIO GUI.\n\n## Expose the MinIO object storage service\n\nElyra utilizes object storage to persist artifacts during pipeline processing. The MinIO GUI provides a basic GUI that is not exposed publicly by default.\n\nTo make the GUI available:\n\n1. In the terminal window create a public endpoint for the MinIO service that was deployed alongside Kubeflow.\n \n   ```\n   $ oc create route edge --service=minio-service --namespace=kubeflow --port=9000 --insecure-policy=Redirect\n   ```\n\n1. Retrieve the public MinIO URL.\n\n   ```\n   $ oc get routes -n kubeflow minio-service -o jsonpath='https://{.spec.host}'\n   ```\n\n1. Open the displayed URL in a web browser to access the MinIO GUI. Log in using the default credentials (`minio`/`minio123`).\n\n   ![Open MinIO GUI](../images/ai/access-minio-gui.png)\n\n\n   Note the `mlpipeline` bucket. This bucket is used by Kubeflow and should not be deleted!\n\n1. Take note of the following information. You'll need it later when you create a runtime configuration in Elyra, so that you can run pipelines in this Kubeflow deployment.\n   - The MinIO GUI URL (`http://minio-service-kubeflow...`).\n   - The MinIO access key (`minio`).\n   - The MinIO secret key (`minio123`).\n\nNext, you'll install JupyterHub with Elyra support.\n\n## Deploy JupyterHub (with Elyra) on OpenShift\n\nIn Open Data Hub, notebooks are served using [JupyterHub](https://jupyter.org/hub). The default deployment includes a container image that has JupyterLab with the Elyra extensions pre-installed.\n\nTo deploy JupyterHub and its dependencies:\n\n1. Open the OpenShift web console.\n1. Navigate to `Operators` > `Installed Operators`.\n1. Select the `Open Data Hub` operator from the list of installed operators.\n1. On the operator details page select the `Details` tab, if it is not opened by default.\n1. Create a new deployment by clicking `Create instance`.\n1. Select `Configure via YAML view`.\n1. Remove the default deployment configuration in the editor.\n1. Copy and paste the following deployment configuration into the editor. This minimal configuration installs common ODH options, JupyterHub, and container images that serve Jupyter notebooks. One of these images, which is named `s2i-lab-elyra:vX.Y.Z`, has JupyterLab with Elyra pre-installed.\n    ```yaml\n    apiVersion: kfdef.apps.kubeflow.org/v1\n    kind: KfDef\n    metadata:\n      annotations:\n        kfctl.kubeflow.io/force-delete: 'false'\n      name: opendatahub\n      namespace: kubeflow\n    spec:\n      applications:\n        # REQUIRED: This contains all of the common options used by all ODH components\n        - kustomizeConfig:\n            repoRef:\n              name: manifests\n              path: odh-common\n          name: odh-common\n        # Deploy Jupyter Hub \n        - kustomizeConfig:\n            parameters:\n              - name: s3_endpoint_url\n                value: s3.odh.com\n            repoRef:\n              name: manifests\n              path: jupyterhub/jupyterhub\n          name: jupyterhub\n        # Deploy Jupyter notebook container images\n        - kustomizeConfig:\n            overlays:\n              - additional\n            repoRef:\n              name: manifests\n              path: jupyterhub/notebook-images\n          name: notebook-images\n      repos:\n        - name: manifests\n          uri: 'https://github.com/opendatahub-io/odh-manifests/tarball/v1.0.11'\n      version: v1.0.11\n    status: {} \n    ```\n\n   Note: Above deployment configuration utilizes version 1.0.11 of the [Open Data Hub manifests](https://github.com/opendatahub-io/odh-manifests/tree/master), which includes Elyra v2.2.4.\n\n   ![Deploy JupyterHub with Elyra](../images/ai/copy-jh-kfdef.png)\n\n1. Click `Create` and wait for the deployment to complete.\n\n   ![Deployment completed](../images/ai/kf-and-odh-deployments-complete.png)\n\nNext, you'll use the JupyterHub spawner to launch Elyra.\n\n## Access Elyra using the JupyterHub Spawner page\n\nThe JupyterHub instance you've deployed includes a [container image that has JupyterLab with the Elyra extensions installed](https://github.com/opendatahub-io/s2i-lab-elyra).\n\nTo run this image:\n\n1. In the terminal window run this command to retrieve the exposed JupyterHub URL:\n   ```\n   $ oc get routes -n kubeflow jupyterhub -o jsonpath='http://{.spec.host}/'\n   ```\n\n1. Open the displayed URL in a browser, and, if required, log in.\n1. On the JupyterHub Spawner page select `s2i-lab-elyra:vX.Y.Z` as notebook image.\n\n   ![Select the Elyra notebook image](../images/ai/select-elyra-image-in-jh-spawner.png)\n\n   Note: The image tag version does not represent the Elyra version.\n\n1. Once the container image was pulled and the container is running the JupyterLab GUI with the Elyra extensions opens in the browser window.\n\n1. In the JupyterLab Launcher window navigate to the `Other` category and open a terminal.\n\n   ![Open terminal in JupyterLab](../images/ai/jupyterlab-open-terminal.png)\n\n1. Enter `elyra-pipeline --version` to display the Elyra version:\n\n   ![Confirm Elyra version](../images/ai/jupyterlab-confirm-elyra-version.png)\n\nNext, you'll create a runtime configuration if you already have Kubeflow deployed in this cluster. If you don't have Kubeflow installed skip the next section.  \n\n## Create a Kubeflow Pipelines runtime configuration\n\nIn Elyra [runtime configurations](/user_guide/runtime-conf.md) are used to provide the tooling access to external resources where pipelines can be executed.\n\nTo create a runtime configuration that allows for running of pipelines on the Kubeflow instance you've deployed:\n\n1. Select the `Runtimes` tab from the JupyterLab side bar.\n\n   ![Open runtime configuration list](../images/ai/open-runtime-configurations-list.png)\n\n1. Click `+` and `New Kubeflow Pipelines runtime`.\n\n1. Enter the following Kubeflow and MinIO configuration information, assuming you've performed a Kubeflow quick install using the linked manifest:\n   - Name: `Local Kubeflow Pipelines`\n   - Kubeflow Pipelines API Endpoint: the output from command \n     ```\n     $ oc get routes -n istio-system istio-ingressgateway -o jsonpath='http://{.spec.host}/pipeline'\n     ```\n   - Kubeflow Pipelines User Namespace: leave empty, if Kubeflow deployment defaults were used\n   - Kubeflow Pipelines API Endpoint Username: leave empty, if Kubeflow deployment defaults were used\n   - Kubeflow Pipelines API  Endpoint Password: leave empty, if Kubeflow deployment defaults were used\n   - Kubeflow Pipelines Engine: `Tekton`, if Kubeflow deployment defaults were used\n   - Cloud Object Storage Endpoint: the output from command \n     ```\n     $ oc get routes -n kubeflow minio-service -o jsonpath='https://{.spec.host}'\n     ```\n\n   - Cloud Object Storage Credentials Secret: leave empty\n   - Cloud Object Storage Username: `minio` if Kubeflow deployment defaults were used, otherwise the appropriate id\n   - Cloud Object Storage Password: `minio123` if Kubeflow deployment defaults were used, otherwise the appropriate password\n   - Cloud Object Storage Bucket Name: `elyra-pipeline-storage`\n1. Save the runtime configuration.\n\nThis concludes the quick deployment and configuration tasks.\n\n## Next steps\n\n- [Verify the deployment by running a basic pipeline](https://elyra.readthedocs.io/en/latest/user_guide/runtime-conf.html#verifying-runtime-configurations)\n- [Learn more about pipelines](../getting_started/tutorials.html#tutorials)\n- [Explore example pipelines](../getting_started/tutorials.html#examples)\n\n## Additional resources\n\n- [OpenShift CLI documentation](https://docs.openshift.com/container-platform/latest/cli_reference/openshift_cli/getting-started-cli.html)\n- [Open Data Hub installation documentation](https://opendatahub.io/docs/getting-started/quick-installation.html)  \n- [KubeFlow installation documentation for Open Data Hub](https://opendatahub.io/docs/kubeflow/installation.html)\n\n","type":"Mdx","contentDigest":"43fadc5497599de253af8a332c0a661a","owner":"gatsby-plugin-mdx","counter":345},"frontmatter":{"title":"Deploying Open Data Hub with Elyra","description":"Deploying Open Data Hub with Elyra"},"exports":{},"rawBody":"---\ntitle: Deploying Open Data Hub with Elyra\ndescription: Deploying Open Data Hub with Elyra\n---\n\nexport const Title = () => (\n  <span>\n    Deploying Open Data Hub with Elyra\n  </span>\n);\n\n<PageDescription>\n\nThis document outlines how to perform a quick deployment of [Kubeflow](https://kubeflow.org), [JupyterHub](https://jupyter.org/hub) and [Elyra](https://github.com/elyra-ai/elyra) on [Open Data Hub (ODH)](https://opendatahub.io/) using the Open Data Hub Operator.\n\n\n</PageDescription>\n\n\nNote the following:\n- The instructions in this document utilize default configurations, which are unlikely to meet the requirements of a production deployment.\n- By completing the steps in this document Kubeflow 1.3, JupyterHub v1.4, and Elyra v2.2.4 are deployed in the `kubeflow` project/namespace.\n- The Kubeflow Central dashboard is unsecured.\n- The JupyterHub GUI is secured by OpenShift. \n \n## Requirements\n\nVerify that the following requirements are met.\n\n- Access to a v4.x Red Hat OpenShift Cluster (16 GB RAM, 6 CPUs, and 45G of disk space) with internet connectivity. \n- The OpenShift CLI (`oc`) is installed locally. \n    - [Installation instructions](https://docs.openshift.com/container-platform/4.7/cli_reference/openshift_cli/getting-started-cli.html) for  Windows and MacOS    \n\n## Prepare for deployment\n\n1. Open the OpenShift web console in a browser and log in.\n1. Copy the login command.\n\n   ![Get oc login command](../images/ai/openshift-get-login-command.png)\n1. Open a terminal window and run the copied command.\n   ```\n   $ oc login --token=TOKEN_VAL --server=https://SERVER:PORT\n   ```\n\n1. Create a new project named `kubeflow`. \n   ```\n   $ oc new-project kubeflow\n   ```\n\n1. Verify that the CLI is using the new `kubeflow` project.\n   ```\n   $ oc project kubeflow\n   ```\n1. Keep the terminal window open.\n\n## Install the Open Data Hub Project Operator on OpenShift\n\nThe Open Data Hub Project Operator manages installation, configuration, and the lifecycle of Open Data Hub projects. The operator is available on OpenShift OperatorHub as a community operator.\n\nTo install the operator:\n\n1. Open the OpenShift web console and log in.\n1. Switch to the `Administrator` view.\n1. Open the projects list (`Home` > `Projects`).\n   ![Open project list in OpenShift](../images/ai/openshift-open-projects.png)\n1. Switch to the `kubeflow` project.\n   ![Open kubeflow project](../images/ai/openshift-view-project.png)  \n1. Open the Operator Hub page (`Operators` > `OperatorHub`).\n1. Search for the `Open Data Hub` operator.\n   ![Install ODH operator](../images/ai/install-odh-operator.png)   \n1. Install the operator, keeping the default values.\n1. Navigate to `Operators` > `Installed Operators` and wait for the operator installation to complete. \n\nNext, you'll install Kubeflow using the operator.\n\n## Deploy Kubeflow on OpenShift\n\nTo deploy Kubeflow using the Open Data Hub operator:\n\n1. Select the `Open Data Hub` operator from the list of installed operators.\n1. On the operator details page select the `Details` tab, if it is not opened by default.\n   ![Deploy application using ODH operator](../images/ai/deploy-app-using-operator.png)\n1. Create a new deployment by clicking `Create instance`.\n1. Select `Configure via YAML view`.\n1. Remove the default deployment configuration in the editor.\n1. Open [this Kubeflow v1.3 deployment file for OpenShift](https://raw.githubusercontent.com/kubeflow/manifests/master/distributions/kfdef/kfctl_openshift_v1.3.0.yaml) in a new browser tab/window.\n1. Copy and paste the content of this file into the editor.\n   ![Deploy Kubeflow using ODH operator](../images/ai/deploy-kubeflow-kfdef.png)\n1. Click `Create` to deploy Kubeflow on the cluster.\n1. In the terminal window monitor the deployment progress by periodically listing pods in the `kubeflow` namespace. Wait until all pods are running. This might take a couple minutes.\n   ```\n   $ oc get pods --namespace kubeflow\n   ```\n   Upon successful deployment you can access the Kubeflow Central dashboard using a public route.\n1. In the terminal window run the following command to retrieve the public Kubeflow Central dashboard URL:\n   ```\n   $ oc get routes -n istio-system istio-ingressgateway -o jsonpath='http://{.spec.host}'\n   ```\n1. Open the displayed URL in a web browser to access the Kubeflow Central dashboard.\n1. Do not select a namespace entry, if you've deployed Kubeflow using the defaults.\n\nThe Kubeflow deployment is complete. As part of this deployment an instance of the MinIO object storage was provisioned. \n\nNext, you'll create a public endpoint for this service that provides you access to the MinIO GUI.\n\n## Expose the MinIO object storage service\n\nElyra utilizes object storage to persist artifacts during pipeline processing. The MinIO GUI provides a basic GUI that is not exposed publicly by default.\n\nTo make the GUI available:\n\n1. In the terminal window create a public endpoint for the MinIO service that was deployed alongside Kubeflow.\n \n   ```\n   $ oc create route edge --service=minio-service --namespace=kubeflow --port=9000 --insecure-policy=Redirect\n   ```\n\n1. Retrieve the public MinIO URL.\n\n   ```\n   $ oc get routes -n kubeflow minio-service -o jsonpath='https://{.spec.host}'\n   ```\n\n1. Open the displayed URL in a web browser to access the MinIO GUI. Log in using the default credentials (`minio`/`minio123`).\n\n   ![Open MinIO GUI](../images/ai/access-minio-gui.png)\n\n\n   Note the `mlpipeline` bucket. This bucket is used by Kubeflow and should not be deleted!\n\n1. Take note of the following information. You'll need it later when you create a runtime configuration in Elyra, so that you can run pipelines in this Kubeflow deployment.\n   - The MinIO GUI URL (`http://minio-service-kubeflow...`).\n   - The MinIO access key (`minio`).\n   - The MinIO secret key (`minio123`).\n\nNext, you'll install JupyterHub with Elyra support.\n\n## Deploy JupyterHub (with Elyra) on OpenShift\n\nIn Open Data Hub, notebooks are served using [JupyterHub](https://jupyter.org/hub). The default deployment includes a container image that has JupyterLab with the Elyra extensions pre-installed.\n\nTo deploy JupyterHub and its dependencies:\n\n1. Open the OpenShift web console.\n1. Navigate to `Operators` > `Installed Operators`.\n1. Select the `Open Data Hub` operator from the list of installed operators.\n1. On the operator details page select the `Details` tab, if it is not opened by default.\n1. Create a new deployment by clicking `Create instance`.\n1. Select `Configure via YAML view`.\n1. Remove the default deployment configuration in the editor.\n1. Copy and paste the following deployment configuration into the editor. This minimal configuration installs common ODH options, JupyterHub, and container images that serve Jupyter notebooks. One of these images, which is named `s2i-lab-elyra:vX.Y.Z`, has JupyterLab with Elyra pre-installed.\n    ```yaml\n    apiVersion: kfdef.apps.kubeflow.org/v1\n    kind: KfDef\n    metadata:\n      annotations:\n        kfctl.kubeflow.io/force-delete: 'false'\n      name: opendatahub\n      namespace: kubeflow\n    spec:\n      applications:\n        # REQUIRED: This contains all of the common options used by all ODH components\n        - kustomizeConfig:\n            repoRef:\n              name: manifests\n              path: odh-common\n          name: odh-common\n        # Deploy Jupyter Hub \n        - kustomizeConfig:\n            parameters:\n              - name: s3_endpoint_url\n                value: s3.odh.com\n            repoRef:\n              name: manifests\n              path: jupyterhub/jupyterhub\n          name: jupyterhub\n        # Deploy Jupyter notebook container images\n        - kustomizeConfig:\n            overlays:\n              - additional\n            repoRef:\n              name: manifests\n              path: jupyterhub/notebook-images\n          name: notebook-images\n      repos:\n        - name: manifests\n          uri: 'https://github.com/opendatahub-io/odh-manifests/tarball/v1.0.11'\n      version: v1.0.11\n    status: {} \n    ```\n\n   Note: Above deployment configuration utilizes version 1.0.11 of the [Open Data Hub manifests](https://github.com/opendatahub-io/odh-manifests/tree/master), which includes Elyra v2.2.4.\n\n   ![Deploy JupyterHub with Elyra](../images/ai/copy-jh-kfdef.png)\n\n1. Click `Create` and wait for the deployment to complete.\n\n   ![Deployment completed](../images/ai/kf-and-odh-deployments-complete.png)\n\nNext, you'll use the JupyterHub spawner to launch Elyra.\n\n## Access Elyra using the JupyterHub Spawner page\n\nThe JupyterHub instance you've deployed includes a [container image that has JupyterLab with the Elyra extensions installed](https://github.com/opendatahub-io/s2i-lab-elyra).\n\nTo run this image:\n\n1. In the terminal window run this command to retrieve the exposed JupyterHub URL:\n   ```\n   $ oc get routes -n kubeflow jupyterhub -o jsonpath='http://{.spec.host}/'\n   ```\n\n1. Open the displayed URL in a browser, and, if required, log in.\n1. On the JupyterHub Spawner page select `s2i-lab-elyra:vX.Y.Z` as notebook image.\n\n   ![Select the Elyra notebook image](../images/ai/select-elyra-image-in-jh-spawner.png)\n\n   Note: The image tag version does not represent the Elyra version.\n\n1. Once the container image was pulled and the container is running the JupyterLab GUI with the Elyra extensions opens in the browser window.\n\n1. In the JupyterLab Launcher window navigate to the `Other` category and open a terminal.\n\n   ![Open terminal in JupyterLab](../images/ai/jupyterlab-open-terminal.png)\n\n1. Enter `elyra-pipeline --version` to display the Elyra version:\n\n   ![Confirm Elyra version](../images/ai/jupyterlab-confirm-elyra-version.png)\n\nNext, you'll create a runtime configuration if you already have Kubeflow deployed in this cluster. If you don't have Kubeflow installed skip the next section.  \n\n## Create a Kubeflow Pipelines runtime configuration\n\nIn Elyra [runtime configurations](/user_guide/runtime-conf.md) are used to provide the tooling access to external resources where pipelines can be executed.\n\nTo create a runtime configuration that allows for running of pipelines on the Kubeflow instance you've deployed:\n\n1. Select the `Runtimes` tab from the JupyterLab side bar.\n\n   ![Open runtime configuration list](../images/ai/open-runtime-configurations-list.png)\n\n1. Click `+` and `New Kubeflow Pipelines runtime`.\n\n1. Enter the following Kubeflow and MinIO configuration information, assuming you've performed a Kubeflow quick install using the linked manifest:\n   - Name: `Local Kubeflow Pipelines`\n   - Kubeflow Pipelines API Endpoint: the output from command \n     ```\n     $ oc get routes -n istio-system istio-ingressgateway -o jsonpath='http://{.spec.host}/pipeline'\n     ```\n   - Kubeflow Pipelines User Namespace: leave empty, if Kubeflow deployment defaults were used\n   - Kubeflow Pipelines API Endpoint Username: leave empty, if Kubeflow deployment defaults were used\n   - Kubeflow Pipelines API  Endpoint Password: leave empty, if Kubeflow deployment defaults were used\n   - Kubeflow Pipelines Engine: `Tekton`, if Kubeflow deployment defaults were used\n   - Cloud Object Storage Endpoint: the output from command \n     ```\n     $ oc get routes -n kubeflow minio-service -o jsonpath='https://{.spec.host}'\n     ```\n\n   - Cloud Object Storage Credentials Secret: leave empty\n   - Cloud Object Storage Username: `minio` if Kubeflow deployment defaults were used, otherwise the appropriate id\n   - Cloud Object Storage Password: `minio123` if Kubeflow deployment defaults were used, otherwise the appropriate password\n   - Cloud Object Storage Bucket Name: `elyra-pipeline-storage`\n1. Save the runtime configuration.\n\nThis concludes the quick deployment and configuration tasks.\n\n## Next steps\n\n- [Verify the deployment by running a basic pipeline](https://elyra.readthedocs.io/en/latest/user_guide/runtime-conf.html#verifying-runtime-configurations)\n- [Learn more about pipelines](../getting_started/tutorials.html#tutorials)\n- [Explore example pipelines](../getting_started/tutorials.html#examples)\n\n## Additional resources\n\n- [OpenShift CLI documentation](https://docs.openshift.com/container-platform/latest/cli_reference/openshift_cli/getting-started-cli.html)\n- [Open Data Hub installation documentation](https://opendatahub.io/docs/getting-started/quick-installation.html)  \n- [KubeFlow installation documentation for Open Data Hub](https://opendatahub.io/docs/kubeflow/installation.html)\n\n","fileAbsolutePath":"/Users/dsobryan/Documents/ElyraOS/elyra-ai-site/src/pages/recipes/deploying-open-data.mdx"}}},"staticQueryHashes":["1364590287","137577622","137577622","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}