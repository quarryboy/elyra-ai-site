{"componentChunkName":"component---src-pages-dev-guide-pipelines-mdx","path":"/dev-guide/pipelines/","result":{"pageContext":{"frontmatter":{"title":"Pipelines","description":"Pipelines"},"relativePagePath":"/dev-guide/pipelines.mdx","titleType":"page","MdxNode":{"id":"40dcb43f-d9d5-51d8-9dfd-c2afad577d63","children":[],"parent":"a7882d74-0810-5178-a1d5-d050e410476b","internal":{"content":"---\ntitle: Pipelines\ndescription: Pipelines\n---\n\nexport const Title = () => (\n  <span>\n    Pipelines\n  </span>\n);\n\n<PageDescription>\n\nThe following sections cover the details relative to working with pipelines in a development capacity.\n\n</PageDescription>\n\n\n## Pipeline definition\n\nBelow is a json representation of the pipeline that is generated by the **Pipeline Editor** and referred to as the _pipeline definition_. \n\nThe pipeline is then submitted to the **Elyra Scheduler** which parses, properly packages and \nsubmits the pipeline definition to the chosen target runtime (e.g. Kubeflow Pipelines).\n\nFor more details on the **pipeline json definition** see it's [json schema](https://github.com/elyra-ai/pipeline-schemas/blob/master/common-pipeline/pipeline-flow/pipeline-flow-v3-schema.json)\n \n### Pipeline definition json example \n\n```json\n{\n\t\"doc_type\": \"pipeline\",\n\t\"version\": \"3.0\",\n\t\"json_schema\": \"http://api.dataplatform.ibm.com/schemas/common-pipeline/pipeline-flow/pipeline-flow-v3-schema.json\",\n\t\"id\": \"582f2dd2-b329-4bfd-8326-3e0dc8c69744\",\n\t\"primary_pipeline\": \"f757f14a-4494-46b5-bb27-aeaa8a065477\",\n\t\"pipelines\": [{\n\t\t\"id\": \"f757f14a-4494-46b5-bb27-aeaa8a065477\",\n\t\t\"nodes\": [{\n\t\t\t\"id\": \"db9f3f5b-b2e3-4824-aadd-c1c6bf652534\",\n\t\t\t\"type\": \"execution_node\",\n\t\t\t\"app_data\": {\n\t\t\t\t\"label\": \"generate-contributions\",\n\t\t\t\t\"component_parameters\": {\n\t\t\t\t\t\"filename\": \"demo-pipelines/generate-contributions.ipynb\",\n\t\t\t\t\t\"runtime_image\": \"tensorflow/tensorflow:2.0.0-py3\",\n\t\t\t\t\t\"outputs\": [\"community_contributions.csv\"],\n\t\t\t\t\t\"env_vars\": [\"GITHUB_TOKEN=xxxx\"],\n\t\t\t\t\t\"dependencies\": [\"contributors.csv\"],\n\t\t\t\t\t\"include_subdirectories\": false\n\t\t\t\t},\n\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\"label\": \"generate-contributions\",\n\t\t\t\t\t\"x_pos\": 387,\n\t\t\t\t\t\"y_pos\": 73,\n\t\t\t\t\t\"description\": \"Notebook file\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"inputs\": [{\n\t\t\t\t\"id\": \"inPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"cardinality\": {\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"max\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"label\": \"Input Port\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}],\n\t\t\t\"outputs\": [{\n\t\t\t\t\"id\": \"outPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"cardinality\": {\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"max\": -1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"label\": \"Output Port\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}]\n\t\t}, {\n\t\t\t\"id\": \"f6584209-6f22-434f-9820-41327b6c749d\",\n\t\t\t\"type\": \"execution_node\",\n\t\t\t\"app_data\": {\n\t\t\t\t\"label\": \"generate-stats\",\n\t\t\t\t\"component_parameters\": {\n\t\t\t\t\t\"filename\": \"demo-pipelines/generate-stats.ipynb\",\n\t\t\t\t\t\"runtime_image\": \"tensorflow/tensorflow:2.0.0-py3\",\n\t\t\t\t\t\"outputs\": [\"community_stats.csv\"],\n\t\t\t\t\t\"env_vars\": [\"GITHUB_TOKEN=xxxx\"],\n\t\t\t\t\t\"dependencies\": [\"contributors.csv\"],\n\t\t\t\t\t\"include_subdirectories\": false\n\t\t\t\t},\n\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\"label\": \"generate-stats\",\n\t\t\t\t\t\"x_pos\": 77,\n\t\t\t\t\t\"y_pos\": 79,\n\t\t\t\t\t\"description\": \"Notebook file\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"inputs\": [{\n\t\t\t\t\"id\": \"inPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"label\": \"\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}],\n\t\t\t\"outputs\": [{\n\t\t\t\t\"id\": \"outPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"label\": \"\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}]\n\t\t}, {\n\t\t\t\"id\": \"079c0e12-eb5f-4fcc-983b-09e011869fee\",\n\t\t\t\"type\": \"execution_node\",\n\t\t\t\"app_data\": {\n\t\t\t\t\"label\": \"overview\",\n\t\t\t\t\"component_parameters\": {\n\t\t\t\t\t\"filename\": \"demo-pipelines/overview.ipynb\",\n\t\t\t\t\t\"runtime_image\": \"elyra/tensorflow:1.15.2-py3\",\n\t\t\t\t\t\"include_subdirectories\": false\n\t\t\t\t},\n\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\"label\": \"overview\",\n\t\t\t\t\t\"x_pos\": 318,\n\t\t\t\t\t\"y_pos\": 312,\n\t\t\t\t\t\"description\": \"Notebook file\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"inputs\": [{\n\t\t\t\t\"id\": \"inPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"label\": \"\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"links\": [{\n\t\t\t\t\t\"node_id_ref\": \"db9f3f5b-b2e3-4824-aadd-c1c6bf652534\",\n\t\t\t\t\t\"port_id_ref\": \"outPort\"\n\t\t\t\t}, {\n\t\t\t\t\t\"node_id_ref\": \"f6584209-6f22-434f-9820-41327b6c749d\",\n\t\t\t\t\t\"port_id_ref\": \"outPort\"\n\t\t\t\t}]\n\t\t\t}],\n\t\t\t\"outputs\": [{\n\t\t\t\t\"id\": \"outPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"label\": \"\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}]\n\t\t}],\n\t\t\"app_data\": {\n\t\t\t\"ui_data\": {\n\t\t\t\t\"comments\": []\n\t\t\t},\n\t\t\t\"title\": \"pipeline-title\",\n\t\t\t\"runtime\": \"kfp\",\n\t\t\t\"runtime-config\": \"kfp-yukked1\",\n                        \"version\": 1\n\t\t},\n\t\t\"runtime_ref\": \"\"\n\t}],\n\t\"schemas\": []\n}\n```\n\n\n## Pipeline Processor Customization\nElyra implements an extensible **pipeline processor engine**, which enables the addition of new pipeline processors utilizing\na service discovery mechanism.  The pipeline processor class hierarchy is depicted here:\n![Pipeline Processor Class Hierachy](../images/ai/pipeline-processor-class-hierarchy.png)\nThis section outlines what is needed to introduce your own runtime for integration with Elyra.  In essence, two criteria must be fulfilled to introduce a new runtime: \n1. A schema describing the necessary runtime metadata\n1. A pipeline processor implementation appropriately associated to the runtime\n\n### Custom Runtime Schema\nThe first requirement for introducing a new runtime for use in Elyra is to define the necessary metadata corresponding to the runtime.  This is accomplished via a JSON schema file describing the necessary metadata used to integrate with the targeted runtime platform.\n\nThis file must reside in the `elyra/metadata/schemas` directory in which Elyra has been installed.  (This location will change to better accommodate custom runtimes in the future.)\n\nThe schema name, represented by the value of the top-level `name` property or, if absent, the file's basename, is what the pipeline engine uses to locate the appropriate pipeline processor implementation.  This value is also set into the pipeline definition's `runtime` property in Elyra's UI, thereby tying the pipeline to the appropriate processor.\n\nThe schema should minimally include property definitions for the Cloud Object Storage (cos) properties found in the built-in schema definitions for [Kubeflow Pipelines](https://github.com/elyra-ai/elyra/blob/62e1964244ec8ada3e63c9c6d39befd7c046df08/elyra/metadata/schemas/kfp.json#L83-L129) and [Apache Airflow](https://github.com/elyra-ai/elyra/blob/62e1964244ec8ada3e63c9c6d39befd7c046df08/elyra/metadata/schemas/airflow.json#L93-L139).\n    \n### Custom Runtime Pipeline Processor Implementation\nThe pipeline processor implementation that corresponds to the targeted runtime platform must be a subclass of `elyra.pipeline.processor.RuntimePipelineProcessor` - which, itself, derives from `elyra.pipeline.processor.PipelineProcessor`.\n\nTo facilitate discovery by the pipeline engine, this implementation must use a value for its [`type` property](https://github.com/elyra-ai/elyra/blob/62e1964244ec8ada3e63c9c6d39befd7c046df08/elyra/pipeline/processor.py#L156) identical to its schema name.\n\n#### Processor Registration\nThe pipeline processor should be registered using **entry_points** with a _name_ that matches both the schema name corresponding to the new runtime and the pipeline processor's `type` property value.  Although this is not technically required, we would like to possibly utilize this during discovery in the future (and is true relative to the built-in processors).\n\nEntrypoint definitions are typically found in the package's **setup.py** or **setup.cfg** files similar to the following example:\n\n```python\n    entry_points = {\n        'elyra.pipeline.processors': [\n            'my_runtime = acme.my_runtime:MyRuntimePipelineProcessor'\n        ]\n    },\n```\nIn this example, and corresponding to the criteria above, pipeline processor `acme.my_runtime.MyRuntimePipelineProcessor` will:\n- derive from `elyra.pipeline.processor.RuntimePipelineProcessor`\n  \n- use a value of `my_runtime` for its `type` property value\n  \n- place a `my_runtime.json` schema file into Elyra's installation's `metadata/schemas` directory\n","type":"Mdx","contentDigest":"b4ac34ba48615fda18cf6391530c3534","owner":"gatsby-plugin-mdx","counter":374},"frontmatter":{"title":"Pipelines","description":"Pipelines"},"exports":{},"rawBody":"---\ntitle: Pipelines\ndescription: Pipelines\n---\n\nexport const Title = () => (\n  <span>\n    Pipelines\n  </span>\n);\n\n<PageDescription>\n\nThe following sections cover the details relative to working with pipelines in a development capacity.\n\n</PageDescription>\n\n\n## Pipeline definition\n\nBelow is a json representation of the pipeline that is generated by the **Pipeline Editor** and referred to as the _pipeline definition_. \n\nThe pipeline is then submitted to the **Elyra Scheduler** which parses, properly packages and \nsubmits the pipeline definition to the chosen target runtime (e.g. Kubeflow Pipelines).\n\nFor more details on the **pipeline json definition** see it's [json schema](https://github.com/elyra-ai/pipeline-schemas/blob/master/common-pipeline/pipeline-flow/pipeline-flow-v3-schema.json)\n \n### Pipeline definition json example \n\n```json\n{\n\t\"doc_type\": \"pipeline\",\n\t\"version\": \"3.0\",\n\t\"json_schema\": \"http://api.dataplatform.ibm.com/schemas/common-pipeline/pipeline-flow/pipeline-flow-v3-schema.json\",\n\t\"id\": \"582f2dd2-b329-4bfd-8326-3e0dc8c69744\",\n\t\"primary_pipeline\": \"f757f14a-4494-46b5-bb27-aeaa8a065477\",\n\t\"pipelines\": [{\n\t\t\"id\": \"f757f14a-4494-46b5-bb27-aeaa8a065477\",\n\t\t\"nodes\": [{\n\t\t\t\"id\": \"db9f3f5b-b2e3-4824-aadd-c1c6bf652534\",\n\t\t\t\"type\": \"execution_node\",\n\t\t\t\"app_data\": {\n\t\t\t\t\"label\": \"generate-contributions\",\n\t\t\t\t\"component_parameters\": {\n\t\t\t\t\t\"filename\": \"demo-pipelines/generate-contributions.ipynb\",\n\t\t\t\t\t\"runtime_image\": \"tensorflow/tensorflow:2.0.0-py3\",\n\t\t\t\t\t\"outputs\": [\"community_contributions.csv\"],\n\t\t\t\t\t\"env_vars\": [\"GITHUB_TOKEN=xxxx\"],\n\t\t\t\t\t\"dependencies\": [\"contributors.csv\"],\n\t\t\t\t\t\"include_subdirectories\": false\n\t\t\t\t},\n\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\"label\": \"generate-contributions\",\n\t\t\t\t\t\"x_pos\": 387,\n\t\t\t\t\t\"y_pos\": 73,\n\t\t\t\t\t\"description\": \"Notebook file\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"inputs\": [{\n\t\t\t\t\"id\": \"inPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"cardinality\": {\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"max\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"label\": \"Input Port\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}],\n\t\t\t\"outputs\": [{\n\t\t\t\t\"id\": \"outPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"cardinality\": {\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"max\": -1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"label\": \"Output Port\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}]\n\t\t}, {\n\t\t\t\"id\": \"f6584209-6f22-434f-9820-41327b6c749d\",\n\t\t\t\"type\": \"execution_node\",\n\t\t\t\"app_data\": {\n\t\t\t\t\"label\": \"generate-stats\",\n\t\t\t\t\"component_parameters\": {\n\t\t\t\t\t\"filename\": \"demo-pipelines/generate-stats.ipynb\",\n\t\t\t\t\t\"runtime_image\": \"tensorflow/tensorflow:2.0.0-py3\",\n\t\t\t\t\t\"outputs\": [\"community_stats.csv\"],\n\t\t\t\t\t\"env_vars\": [\"GITHUB_TOKEN=xxxx\"],\n\t\t\t\t\t\"dependencies\": [\"contributors.csv\"],\n\t\t\t\t\t\"include_subdirectories\": false\n\t\t\t\t},\n\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\"label\": \"generate-stats\",\n\t\t\t\t\t\"x_pos\": 77,\n\t\t\t\t\t\"y_pos\": 79,\n\t\t\t\t\t\"description\": \"Notebook file\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"inputs\": [{\n\t\t\t\t\"id\": \"inPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"label\": \"\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}],\n\t\t\t\"outputs\": [{\n\t\t\t\t\"id\": \"outPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"label\": \"\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}]\n\t\t}, {\n\t\t\t\"id\": \"079c0e12-eb5f-4fcc-983b-09e011869fee\",\n\t\t\t\"type\": \"execution_node\",\n\t\t\t\"app_data\": {\n\t\t\t\t\"label\": \"overview\",\n\t\t\t\t\"component_parameters\": {\n\t\t\t\t\t\"filename\": \"demo-pipelines/overview.ipynb\",\n\t\t\t\t\t\"runtime_image\": \"elyra/tensorflow:1.15.2-py3\",\n\t\t\t\t\t\"include_subdirectories\": false\n\t\t\t\t},\n\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\"label\": \"overview\",\n\t\t\t\t\t\"x_pos\": 318,\n\t\t\t\t\t\"y_pos\": 312,\n\t\t\t\t\t\"description\": \"Notebook file\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"inputs\": [{\n\t\t\t\t\"id\": \"inPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"label\": \"\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"links\": [{\n\t\t\t\t\t\"node_id_ref\": \"db9f3f5b-b2e3-4824-aadd-c1c6bf652534\",\n\t\t\t\t\t\"port_id_ref\": \"outPort\"\n\t\t\t\t}, {\n\t\t\t\t\t\"node_id_ref\": \"f6584209-6f22-434f-9820-41327b6c749d\",\n\t\t\t\t\t\"port_id_ref\": \"outPort\"\n\t\t\t\t}]\n\t\t\t}],\n\t\t\t\"outputs\": [{\n\t\t\t\t\"id\": \"outPort\",\n\t\t\t\t\"app_data\": {\n\t\t\t\t\t\"ui_data\": {\n\t\t\t\t\t\t\"label\": \"\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}]\n\t\t}],\n\t\t\"app_data\": {\n\t\t\t\"ui_data\": {\n\t\t\t\t\"comments\": []\n\t\t\t},\n\t\t\t\"title\": \"pipeline-title\",\n\t\t\t\"runtime\": \"kfp\",\n\t\t\t\"runtime-config\": \"kfp-yukked1\",\n                        \"version\": 1\n\t\t},\n\t\t\"runtime_ref\": \"\"\n\t}],\n\t\"schemas\": []\n}\n```\n\n\n## Pipeline Processor Customization\nElyra implements an extensible **pipeline processor engine**, which enables the addition of new pipeline processors utilizing\na service discovery mechanism.  The pipeline processor class hierarchy is depicted here:\n![Pipeline Processor Class Hierachy](../images/ai/pipeline-processor-class-hierarchy.png)\nThis section outlines what is needed to introduce your own runtime for integration with Elyra.  In essence, two criteria must be fulfilled to introduce a new runtime: \n1. A schema describing the necessary runtime metadata\n1. A pipeline processor implementation appropriately associated to the runtime\n\n### Custom Runtime Schema\nThe first requirement for introducing a new runtime for use in Elyra is to define the necessary metadata corresponding to the runtime.  This is accomplished via a JSON schema file describing the necessary metadata used to integrate with the targeted runtime platform.\n\nThis file must reside in the `elyra/metadata/schemas` directory in which Elyra has been installed.  (This location will change to better accommodate custom runtimes in the future.)\n\nThe schema name, represented by the value of the top-level `name` property or, if absent, the file's basename, is what the pipeline engine uses to locate the appropriate pipeline processor implementation.  This value is also set into the pipeline definition's `runtime` property in Elyra's UI, thereby tying the pipeline to the appropriate processor.\n\nThe schema should minimally include property definitions for the Cloud Object Storage (cos) properties found in the built-in schema definitions for [Kubeflow Pipelines](https://github.com/elyra-ai/elyra/blob/62e1964244ec8ada3e63c9c6d39befd7c046df08/elyra/metadata/schemas/kfp.json#L83-L129) and [Apache Airflow](https://github.com/elyra-ai/elyra/blob/62e1964244ec8ada3e63c9c6d39befd7c046df08/elyra/metadata/schemas/airflow.json#L93-L139).\n    \n### Custom Runtime Pipeline Processor Implementation\nThe pipeline processor implementation that corresponds to the targeted runtime platform must be a subclass of `elyra.pipeline.processor.RuntimePipelineProcessor` - which, itself, derives from `elyra.pipeline.processor.PipelineProcessor`.\n\nTo facilitate discovery by the pipeline engine, this implementation must use a value for its [`type` property](https://github.com/elyra-ai/elyra/blob/62e1964244ec8ada3e63c9c6d39befd7c046df08/elyra/pipeline/processor.py#L156) identical to its schema name.\n\n#### Processor Registration\nThe pipeline processor should be registered using **entry_points** with a _name_ that matches both the schema name corresponding to the new runtime and the pipeline processor's `type` property value.  Although this is not technically required, we would like to possibly utilize this during discovery in the future (and is true relative to the built-in processors).\n\nEntrypoint definitions are typically found in the package's **setup.py** or **setup.cfg** files similar to the following example:\n\n```python\n    entry_points = {\n        'elyra.pipeline.processors': [\n            'my_runtime = acme.my_runtime:MyRuntimePipelineProcessor'\n        ]\n    },\n```\nIn this example, and corresponding to the criteria above, pipeline processor `acme.my_runtime.MyRuntimePipelineProcessor` will:\n- derive from `elyra.pipeline.processor.RuntimePipelineProcessor`\n  \n- use a value of `my_runtime` for its `type` property value\n  \n- place a `my_runtime.json` schema file into Elyra's installation's `metadata/schemas` directory\n","fileAbsolutePath":"/Users/dsobryan/Documents/ElyraOS/elyra-ai-site/src/pages/dev-guide/pipelines.mdx"}}},"staticQueryHashes":["1364590287","137577622","137577622","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}