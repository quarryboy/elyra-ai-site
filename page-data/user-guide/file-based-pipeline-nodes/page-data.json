{"componentChunkName":"component---src-pages-user-guide-file-based-pipeline-nodes-mdx","path":"/user-guide/file-based-pipeline-nodes/","result":{"pageContext":{"frontmatter":{"title":"Best practices for file-based pipeline nodes","description":"Best practices for file-based pipeline nodes"},"relativePagePath":"/user-guide/file-based-pipeline-nodes.mdx","titleType":"page","MdxNode":{"id":"62516198-99d3-5dd2-a20c-10204f9be20c","children":[],"parent":"d7986cdf-dd71-5f70-9e56-94d3f1f5e80d","internal":{"content":"---\ntitle: Best practices for file-based pipeline nodes\ndescription: Best practices for file-based pipeline nodes\n---\n\nexport const Title = () => (\n  <span>\n    Best practices for file-based pipeline nodes\n  </span>\n);\n\n<PageDescription>\n\n[Generic pipelines and typed pipelines](pipelines.md) support natively file-based nodes for Jupyter notebooks, Python scripts, and R scripts. In order to support heterogeneous execution - that is making them runnable in any runtime environment (JupyterLab, Kubeflow Pipelines, and Apache Airflow) - follow the guidelines listed below.\n\n</PageDescription>\n\n## Runtime image\n\nOn Kubeflow Pipelines and Apache Airflow, notebooks and scripts are executed in containers. Elyra provides [example runtime images](runtime-image-conf.md) to get you started, but you should consider utilizing [purpose-built images](../recipes/creating-a-custom-runtime-image.md) instead. If possible, pre-install all software prerequisites in the runtime image you are using instead of installing them on the fly (e.g. by running `pip install my-package==1.2.3` in a notebook cell).\n\n## File I/O \n\nIn runtime environments (like Kubeflow Pipelines and Apache Airflow) where containers are used to run notebooks/scripts special consideration must be given to file input and output operations.\n\n### File input\n\nIf a notebook/script requires access to files that are stored on you local system, those files must be declared as _File dependencies_. Elyra collects declared files and uploads them to cloud storage and makes them available to the notebook/script at runtime.\n\n![Define file dependencies](../images/ai/vpe-node-input-files.png)\n\nFile dependencies must be located in the notebook/script file directory or a subdirectory of that location. Symlinks can be used to avoid the need to maintain multiple copies if files are shared among pipelines.\n\nValid directory layout examples:\n\n```\n./my-pipeline.pipeline\n./my-notebook.ipynb\n./a-notebook-symlink.ipynb      # can reference a notebook in any local directory\n./a-dependency-file               \n./a-symlink                     # can reference any file or directory\n./a-subdir/a-dependency-file\n./a-subdir/a-symlink            # can reference any file or directory\n./a-subdir/a-script-symlink.py  # can reference a script in any local directory\n```\n\nInvalid directory layout examples:\n```\n./my-pipeline.pipeline\n./my-script.py\n../my-other-notebook.ipynb     # must be symlinked\n../a-dependency-in-parent-dir  # must be symlinked \n/some/dir/some-dependency      # must be symlinked\n```\n\n### File output\n\nAll changes to the file system (e.g. new files or modified files) are discarded after processing of the notebook/script has completed. To retain these files you must store those files on cloud storage, or declare those files as output files in the notebook/script node properties. \n\n![Define output files](../images/ai/vpe-node-output-files.png)\n\n## Environment variables\n\nYou can customize notebooks/scripts by setting environment variables in the pipeline node. Environment variable values are not shared across nodes belonging to the same pipeline.\n\n![Define environment variables](../images/ai/vpe-node-env-vars.png)\n\nThe Visual Pipeline Editor can detect which environment variables notebooks/scripts are accessing and automatically adds those variables to the runtime properties if the following approaches are used to read variable values:\n\n- Python\n  - `os.getenv(key[,...])`\n  - `os.environ[key]`\n  - `os.environ.get(key[,...])`\n\n- R script\n  - `Sys.getenv(...)`\n\nRefer to the next section for a list of proprietary environment variables that cannot be modified using the node properties settings.\n\n## Proprietary environment variables\n\nElyra makes a set of proprietary environment variables available to notebooks and scripts during execution. Unless indicated otherwise, these variables are defined in all runtime environments.\n\n![Access proprietary environment variables](../images/ai/elyra-env-vars.png)\n\n### ELYRA_RUN_NAME\n\n`ELYRA_RUN_NAME` is an identifier that is unique for each pipeline run but the same for all nodes in the pipeline. You can use this identifier to generate predictable file names.\n\nExample value: `unicorn-0617153527`\n\n### ELYRA_RUNTIME_ENV\n\n`ELYRA_RUNTIME_ENV` identifies the runtime environment that the \nnotebook or script is executed in:\n- `local` - JupyterLab\n- `kfp` - Kubeflow Pipelines\n- `airflow` - Apache Airflow\n","type":"Mdx","contentDigest":"f35883feb2a769f676fb99cabd7943df","owner":"gatsby-plugin-mdx","counter":333},"frontmatter":{"title":"Best practices for file-based pipeline nodes","description":"Best practices for file-based pipeline nodes"},"exports":{},"rawBody":"---\ntitle: Best practices for file-based pipeline nodes\ndescription: Best practices for file-based pipeline nodes\n---\n\nexport const Title = () => (\n  <span>\n    Best practices for file-based pipeline nodes\n  </span>\n);\n\n<PageDescription>\n\n[Generic pipelines and typed pipelines](pipelines.md) support natively file-based nodes for Jupyter notebooks, Python scripts, and R scripts. In order to support heterogeneous execution - that is making them runnable in any runtime environment (JupyterLab, Kubeflow Pipelines, and Apache Airflow) - follow the guidelines listed below.\n\n</PageDescription>\n\n## Runtime image\n\nOn Kubeflow Pipelines and Apache Airflow, notebooks and scripts are executed in containers. Elyra provides [example runtime images](runtime-image-conf.md) to get you started, but you should consider utilizing [purpose-built images](../recipes/creating-a-custom-runtime-image.md) instead. If possible, pre-install all software prerequisites in the runtime image you are using instead of installing them on the fly (e.g. by running `pip install my-package==1.2.3` in a notebook cell).\n\n## File I/O \n\nIn runtime environments (like Kubeflow Pipelines and Apache Airflow) where containers are used to run notebooks/scripts special consideration must be given to file input and output operations.\n\n### File input\n\nIf a notebook/script requires access to files that are stored on you local system, those files must be declared as _File dependencies_. Elyra collects declared files and uploads them to cloud storage and makes them available to the notebook/script at runtime.\n\n![Define file dependencies](../images/ai/vpe-node-input-files.png)\n\nFile dependencies must be located in the notebook/script file directory or a subdirectory of that location. Symlinks can be used to avoid the need to maintain multiple copies if files are shared among pipelines.\n\nValid directory layout examples:\n\n```\n./my-pipeline.pipeline\n./my-notebook.ipynb\n./a-notebook-symlink.ipynb      # can reference a notebook in any local directory\n./a-dependency-file               \n./a-symlink                     # can reference any file or directory\n./a-subdir/a-dependency-file\n./a-subdir/a-symlink            # can reference any file or directory\n./a-subdir/a-script-symlink.py  # can reference a script in any local directory\n```\n\nInvalid directory layout examples:\n```\n./my-pipeline.pipeline\n./my-script.py\n../my-other-notebook.ipynb     # must be symlinked\n../a-dependency-in-parent-dir  # must be symlinked \n/some/dir/some-dependency      # must be symlinked\n```\n\n### File output\n\nAll changes to the file system (e.g. new files or modified files) are discarded after processing of the notebook/script has completed. To retain these files you must store those files on cloud storage, or declare those files as output files in the notebook/script node properties. \n\n![Define output files](../images/ai/vpe-node-output-files.png)\n\n## Environment variables\n\nYou can customize notebooks/scripts by setting environment variables in the pipeline node. Environment variable values are not shared across nodes belonging to the same pipeline.\n\n![Define environment variables](../images/ai/vpe-node-env-vars.png)\n\nThe Visual Pipeline Editor can detect which environment variables notebooks/scripts are accessing and automatically adds those variables to the runtime properties if the following approaches are used to read variable values:\n\n- Python\n  - `os.getenv(key[,...])`\n  - `os.environ[key]`\n  - `os.environ.get(key[,...])`\n\n- R script\n  - `Sys.getenv(...)`\n\nRefer to the next section for a list of proprietary environment variables that cannot be modified using the node properties settings.\n\n## Proprietary environment variables\n\nElyra makes a set of proprietary environment variables available to notebooks and scripts during execution. Unless indicated otherwise, these variables are defined in all runtime environments.\n\n![Access proprietary environment variables](../images/ai/elyra-env-vars.png)\n\n### ELYRA_RUN_NAME\n\n`ELYRA_RUN_NAME` is an identifier that is unique for each pipeline run but the same for all nodes in the pipeline. You can use this identifier to generate predictable file names.\n\nExample value: `unicorn-0617153527`\n\n### ELYRA_RUNTIME_ENV\n\n`ELYRA_RUNTIME_ENV` identifies the runtime environment that the \nnotebook or script is executed in:\n- `local` - JupyterLab\n- `kfp` - Kubeflow Pipelines\n- `airflow` - Apache Airflow\n","fileAbsolutePath":"/Users/dsobryan/Documents/ElyraOS/elyra-ai-site/src/pages/user-guide/file-based-pipeline-nodes.mdx"}}},"staticQueryHashes":["1364590287","137577622","137577622","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}